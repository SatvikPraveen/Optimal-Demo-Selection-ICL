{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCJ4uajBDU0E"
      },
      "outputs": [],
      "source": [
        "# Gemma AG News\n",
        "\n",
        "# final accuracy method\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class RDESelector:\n",
        "    def __init__(self, demo_pool, num_classes, q_table=None):\n",
        "        self.demo_pool = demo_pool\n",
        "        self.num_classes = num_classes\n",
        "        self.q_table = q_table if q_table else {}\n",
        "        self.alpha = 0.1  # Learning rate\n",
        "        self.gamma = 0.9  # Discount factor\n",
        "        self.epsilon = 0.2  # Exploration rate\n",
        "\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.demo_embeddings = self.embedding_model.encode(\n",
        "            [d['text'] for d in demo_pool],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "    def diversity_score(self, selected_indices):\n",
        "        label_counts = np.zeros(self.num_classes)\n",
        "        for idx in selected_indices:\n",
        "            label_counts[self.demo_pool[idx]['label']] += 1\n",
        "        entropy = -np.sum((label_counts/np.sum(label_counts)) *\n",
        "                        np.log(label_counts/np.sum(label_counts) + 1e-9))\n",
        "        return entropy\n",
        "\n",
        "    def get_state_key(self, current_state):\n",
        "        return tuple(sorted(current_state['selected']))\n",
        "\n",
        "    def select_demos(self, input_sample, k=5):\n",
        "        selected = []\n",
        "        state = {'input': input_sample, 'selected': []}\n",
        "\n",
        "        input_embedding = self.embedding_model.encode(\n",
        "            input_sample['text'],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        for _ in range(k):\n",
        "            valid_demos = [int(i) for i in range(len(self.demo_pool))\n",
        "                         if i not in state['selected']]\n",
        "\n",
        "            if np.random.random() < self.epsilon:\n",
        "                action = int(np.random.choice(valid_demos))\n",
        "            else:\n",
        "                q_values = [self.q_table.get((self.get_state_key(state), a), 0)\n",
        "                          for a in valid_demos]\n",
        "                action = int(valid_demos[np.argmax(q_values)])\n",
        "\n",
        "            selected.append(action)\n",
        "            state['selected'].append(action)\n",
        "\n",
        "            next_state = state.copy()\n",
        "            next_state['selected'] = selected.copy()\n",
        "            reward = self.calculate_reward(input_embedding, selected)\n",
        "\n",
        "            current_state_key = self.get_state_key(state)\n",
        "            next_max = max([self.q_table.get((self.get_state_key(next_state), a), 0)\n",
        "                          for a in valid_demos if a != action], default=0)\n",
        "\n",
        "            self.q_table[(current_state_key, action)] = (\n",
        "                (1 - self.alpha) * self.q_table.get((current_state_key, action), 0) +\n",
        "                self.alpha * (reward + self.gamma * next_max)\n",
        "            )\n",
        "\n",
        "        return [self.demo_pool[i] for i in selected]\n",
        "\n",
        "    def calculate_reward(self, input_embedding, selected_indices):\n",
        "        demo_embeddings = self.demo_embeddings[selected_indices]\n",
        "        similarities = np.dot(demo_embeddings, input_embedding)\n",
        "        relevance = np.mean(similarities)\n",
        "        diversity = self.diversity_score(selected_indices)\n",
        "        max_entropy = np.log(self.num_classes)\n",
        "        normalized_diversity = diversity / max_entropy\n",
        "        return 0.5 * normalized_diversity + 0.5 * relevance\n",
        "\n",
        "\n",
        "ag_news = load_dataset(\"ag_news\")\n",
        "train_demos = ag_news[\"train\"]#.select(range(2500))\n",
        "test_samples = ag_news[\"test\"]#.select(range(700))\n",
        "\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "rde_selector = RDESelector(train_demos, num_classes=4)\n",
        "import re\n",
        "def format_prompt(demos, test_sample):\n",
        "      prompt = \"\"\"Classify news articles into these categories:\n",
        "                0: World\n",
        "                1: Sports\n",
        "                2: Business\n",
        "                3: Sci/Tech\n",
        "\n",
        "                Examples:\"\"\"\n",
        "\n",
        "      for demo in demos:\n",
        "          prompt += f\"\\nArticle: {demo['text'][:200]}\\nLabel: {demo['label']}\"\n",
        "\n",
        "      prompt += f\"\\n\\nNew Article: {test_sample['text'][:200]}\\nLabel:\"\n",
        "      return prompt\n",
        "\n",
        "\n",
        "\n",
        "correct = 0\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    selected_demos = rde_selector.select_demos(sample, k=5)\n",
        "    prompt = format_prompt(selected_demos, sample)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=2,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        top_k=1,\n",
        "        num_return_sequences=1\n",
        "    )\n",
        "\n",
        "    generated_text = outputs[0]['generated_text']\n",
        "    match = re.search(r'Label:\\s*(\\d+)', generated_text)\n",
        "    predicted_label = match.group(1) if match else None\n",
        "\n",
        "    actual_label = str(sample['label'])\n",
        "\n",
        "    color_code = \"\\033[92m\" if str(actual_label) == predicted_label else \"\\033[91m\"\n",
        "    print(f\"Sample {idx+1}:\")\n",
        "    print(f\"  Predicted: {predicted_label} | Actual: {actual_label}\")\n",
        "    print(f\"  Text: {sample['text'][:100]}...\")\n",
        "    print(f\"{color_code}  Result: {'CORRECT' if str(actual_label) == predicted_label else 'INCORRECT'}\\033[0m\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    if predicted_label == actual_label:\n",
        "        correct += 1\n",
        "\n",
        "print(f\"\\nFinal Accuracy: {correct/len(test_samples):.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT2 AGNews\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, GPT2LMHeadModel, pipeline\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class RDESelector:\n",
        "    def __init__(self, demo_pool, num_classes, q_table=None):\n",
        "        self.demo_pool = demo_pool\n",
        "        self.num_classes = num_classes\n",
        "        self.q_table = q_table if q_table else {}\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 0.2\n",
        "\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.demo_embeddings = self.embedding_model.encode(\n",
        "            [d['text'] for d in demo_pool],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "    def diversity_score(self, selected_indices):\n",
        "        label_counts = np.zeros(self.num_classes)\n",
        "        for idx in selected_indices:\n",
        "            label_counts[self.demo_pool[idx]['label']] += 1\n",
        "        entropy = -np.sum((label_counts/np.sum(label_counts)) *\n",
        "                        np.log(label_counts/np.sum(label_counts) + 1e-9))\n",
        "        return entropy\n",
        "\n",
        "    def get_state_key(self, current_state):\n",
        "        return tuple(sorted(current_state['selected']))\n",
        "\n",
        "    def select_demos(self, input_sample, k=5):\n",
        "        selected = []\n",
        "        state = {'input': input_sample, 'selected': []}\n",
        "        input_embedding = self.embedding_model.encode(\n",
        "            input_sample['text'],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        for _ in range(k):\n",
        "            valid_demos = [int(i) for i in range(len(self.demo_pool))\n",
        "                         if i not in state['selected']]\n",
        "\n",
        "            if np.random.random() < self.epsilon:\n",
        "                action = int(np.random.choice(valid_demos))\n",
        "            else:\n",
        "                q_values = [self.q_table.get((self.get_state_key(state), a), 0)\n",
        "                          for a in valid_demos]\n",
        "                action = int(valid_demos[np.argmax(q_values)])\n",
        "\n",
        "            selected.append(action)\n",
        "            state['selected'].append(action)\n",
        "            next_state = state.copy()\n",
        "            next_state['selected'] = selected.copy()\n",
        "            reward = self.calculate_reward(input_embedding, selected)\n",
        "\n",
        "            current_state_key = self.get_state_key(state)\n",
        "            next_max = max([self.q_table.get((self.get_state_key(next_state), a), 0)\n",
        "                          for a in valid_demos if a != action], default=0)\n",
        "\n",
        "            self.q_table[(current_state_key, action)] = (\n",
        "                (1 - self.alpha) * self.q_table.get((current_state_key, action), 0) +\n",
        "                self.alpha * (reward + self.gamma * next_max)\n",
        "            )\n",
        "\n",
        "        return [self.demo_pool[i] for i in selected]\n",
        "\n",
        "    def calculate_reward(self, input_embedding, selected_indices):\n",
        "        demo_embeddings = self.demo_embeddings[selected_indices]\n",
        "        similarities = np.dot(demo_embeddings, input_embedding)\n",
        "        relevance = np.mean(similarities)\n",
        "        diversity = self.diversity_score(selected_indices)\n",
        "        max_entropy = np.log(self.num_classes)\n",
        "        normalized_diversity = diversity / max_entropy\n",
        "        return 0.5 * normalized_diversity + 0.5 * relevance\n",
        "\n",
        "ag_news = load_dataset(\"ag_news\")\n",
        "train_demos = ag_news[\"train\"]\n",
        "test_samples = ag_news[\"test\"]\n",
        "\n",
        "model_id = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "model.eval()\n",
        "\n",
        "rde_selector = RDESelector(train_demos, num_classes=4)\n",
        "\n",
        "def format_prompt(demos, test_sample):\n",
        "    prompt = \"Classify news articles into one of these categories:\\n\"\n",
        "    prompt += \"0: World News\\n1: Sports\\n2: Business\\n3: Science/Tech\\n\\nExamples:\\n\"\n",
        "\n",
        "    for demo in demos:\n",
        "        prompt += f\"Article: {demo['text']}\\nCategory: {demo['label']}\\n\\n\"\n",
        "\n",
        "    prompt += f\"New Article: {test_sample['text']}\\nCategory:\"\n",
        "    return prompt\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "invalid_predictions = 0\n",
        "\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    selected_demos = rde_selector.select_demos(sample, k=5)\n",
        "    prompt = format_prompt(selected_demos, sample)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=3,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    prediction_part = decoded.split(\"Category:\")[-1].strip()\n",
        "    prediction = ''.join(filter(str.isdigit, prediction_part))\n",
        "\n",
        "    try:\n",
        "        predicted_label = int(prediction[0]) if prediction else -1\n",
        "    except:\n",
        "        predicted_label = -1\n",
        "        invalid_predictions += 1\n",
        "\n",
        "    actual_label = sample['label']\n",
        "\n",
        "    if predicted_label == actual_label:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "    color_code = \"\\033[92m\" if str(actual_label) == str(predicted_label) else \"\\033[91m\"\n",
        "    print(f\"Sample {idx+1}:\")\n",
        "    print(f\"  Predicted: {predicted_label} | Actual: {actual_label}\")\n",
        "    # print(f\"  Text: {sample['text'][:100]}...\")\n",
        "    print(f\"{color_code}  Result: {'CORRECT' if str(actual_label) == str(predicted_label) else 'INCORRECT'}\\033[0m\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    if (idx + 1) % 100 == 0:\n",
        "        print(f\"Processed {idx+1} samples | Current Accuracy: {correct/total:.2%}\")\n",
        "\n",
        "print(f\"\\nFinal Results:\")\n",
        "print(f\"Correct predictions: {correct}/{len(test_samples)}\")\n",
        "print(f\"Invalid predictions: {invalid_predictions}\")\n",
        "print(f\"Final Accuracy: {correct/len(test_samples):.2%}\")\n"
      ],
      "metadata": {
        "id": "84fqneb4DX4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama AG News\n",
        "\n",
        "# final accuracy method\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class RDESelector:\n",
        "    def __init__(self, demo_pool, num_classes, q_table=None):\n",
        "        self.demo_pool = demo_pool\n",
        "        self.num_classes = num_classes\n",
        "        self.q_table = q_table if q_table else {}\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 0.2\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.demo_embeddings = self.embedding_model.encode(\n",
        "            [d['text'] for d in demo_pool],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "    def diversity_score(self, selected_indices):\n",
        "        label_counts = np.zeros(self.num_classes)\n",
        "        for idx in selected_indices:\n",
        "            label_counts[self.demo_pool[idx]['label']] += 1\n",
        "        entropy = -np.sum((label_counts/np.sum(label_counts)) *\n",
        "                        np.log(label_counts/np.sum(label_counts) + 1e-9))\n",
        "        return entropy\n",
        "\n",
        "    def get_state_key(self, current_state):\n",
        "        return tuple(sorted(current_state['selected']))\n",
        "\n",
        "    def select_demos(self, input_sample, k=5):\n",
        "        selected = []\n",
        "        state = {'input': input_sample, 'selected': []}\n",
        "        input_embedding = self.embedding_model.encode(\n",
        "            input_sample['text'],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        for _ in range(k):\n",
        "            valid_demos = [int(i) for i in range(len(self.demo_pool))\n",
        "                         if i not in state['selected']]\n",
        "\n",
        "            if np.random.random() < self.epsilon:\n",
        "                action = int(np.random.choice(valid_demos))\n",
        "            else:\n",
        "                q_values = [self.q_table.get((self.get_state_key(state), a), 0)\n",
        "                          for a in valid_demos]\n",
        "                action = int(valid_demos[np.argmax(q_values)])\n",
        "\n",
        "            selected.append(action)\n",
        "            state['selected'].append(action)\n",
        "            next_state = state.copy()\n",
        "            next_state['selected'] = selected.copy()\n",
        "            reward = self.calculate_reward(input_embedding, selected)\n",
        "\n",
        "            current_state_key = self.get_state_key(state)\n",
        "            next_max = max([self.q_table.get((self.get_state_key(next_state), a), 0)\n",
        "                          for a in valid_demos if a != action], default=0)\n",
        "\n",
        "            self.q_table[(current_state_key, action)] = (\n",
        "                (1 - self.alpha) * self.q_table.get((current_state_key, action), 0) +\n",
        "                self.alpha * (reward + self.gamma * next_max)\n",
        "            )\n",
        "\n",
        "        return [self.demo_pool[i] for i in selected]\n",
        "\n",
        "    def calculate_reward(self, input_embedding, selected_indices):\n",
        "        demo_embeddings = self.demo_embeddings[selected_indices]\n",
        "        similarities = np.dot(demo_embeddings, input_embedding)\n",
        "        relevance = np.mean(similarities)\n",
        "        diversity = self.diversity_score(selected_indices)\n",
        "        max_entropy = np.log(self.num_classes)\n",
        "        normalized_diversity = diversity / max_entropy\n",
        "        return 0.5 * normalized_diversity + 0.5 * relevance\n",
        "\n",
        "\n",
        "ag_news = load_dataset(\"ag_news\")\n",
        "train_demos = ag_news[\"train\"]#.shuffle().select(range(100)).with_format(\"python\")\n",
        "test_samples = ag_news[\"test\"]#.shuffle().select(range(100)).with_format(\"python\")\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "rde_selector = RDESelector(train_demos, num_classes=4)\n",
        "\n",
        "def format_prompt(demos, test_sample):\n",
        "    prompt = \"Classify news articles into categories: World (0), Sports (1), Business (2), Sci/Tech (3)\\n\\n\"\n",
        "    for demo in demos:\n",
        "        prompt += f\"Article: {demo['text']}\\nLabel: {demo['label']}\\n\\n\"\n",
        "    prompt += f\"Article: {test_sample['text']}\\nLabel:\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "correct = 0\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    selected_demos = rde_selector.select_demos(sample, k=5)\n",
        "    prompt = format_prompt(selected_demos, sample)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=2,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    predicted_label = outputs[0]['generated_text'].strip()\n",
        "    actual_label = sample['label']\n",
        "\n",
        "    # color_code = \"\\033[92m\" if str(actual_label) == predicted_label else \"\\033[91m\"\n",
        "    # print(f\"Sample {idx+1}:\")\n",
        "    # print(f\"  Predicted: {predicted_label} | Actual: {actual_label}\")\n",
        "    # print(f\"  Text: {sample['text'][:100]}...\")\n",
        "    # print(f\"{color_code}  Result: {'CORRECT' if str(actual_label) == predicted_label else 'INCORRECT'}\\033[0m\")\n",
        "    # print(\"-\" * 80)\n",
        "\n",
        "    if str(actual_label) == predicted_label:\n",
        "        correct += 1\n",
        "\n",
        "print(f\"\\nFinal Accuracy: {correct/len(test_samples):.2%}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S-tgEDWmDawE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}