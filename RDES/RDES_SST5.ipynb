{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyDnDDwqDkmR"
      },
      "outputs": [],
      "source": [
        "# GPT2 SST5\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class RDESelector:\n",
        "    def __init__(self, demo_pool, num_classes, q_table=None):\n",
        "        self.demo_pool = demo_pool\n",
        "        self.num_classes = num_classes\n",
        "        self.q_table = q_table if q_table else {}\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 0.2\n",
        "\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.demo_embeddings = self.embedding_model.encode(\n",
        "            [d['text'] for d in demo_pool],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "    def diversity_score(self, selected_indices):\n",
        "        answer_counts = np.zeros(self.num_classes)\n",
        "        for idx in selected_indices:\n",
        "            answer_counts[self.demo_pool[idx]['label']] += 1\n",
        "        entropy = -np.sum((answer_counts/np.sum(answer_counts)) *\n",
        "                        np.log(answer_counts/np.sum(answer_counts) + 1e-9))\n",
        "        return entropy\n",
        "\n",
        "    def get_state_key(self, current_state):\n",
        "        return tuple(sorted(current_state['selected']))\n",
        "\n",
        "    def select_demos(self, input_sample, k=5):\n",
        "        selected = []\n",
        "        state = {'input': input_sample, 'selected': []}\n",
        "\n",
        "        input_embedding = self.embedding_model.encode(\n",
        "            input_sample['text'],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        for _ in range(k):\n",
        "            valid_demos = [i for i in range(len(self.demo_pool))\n",
        "                         if i not in state['selected']]\n",
        "\n",
        "            if np.random.random() < self.epsilon:\n",
        "                action = int(np.random.choice(valid_demos))\n",
        "            else:\n",
        "                q_values = [self.q_table.get((self.get_state_key(state), a), 0)\n",
        "                          for a in valid_demos]\n",
        "                action = int(valid_demos[np.argmax(q_values)])\n",
        "\n",
        "            selected.append(action)\n",
        "            state['selected'].append(action)\n",
        "\n",
        "            next_state = state.copy()\n",
        "            next_state['selected'] = selected.copy()\n",
        "            reward = self.calculate_reward(input_embedding, selected)\n",
        "\n",
        "            current_state_key = self.get_state_key(state)\n",
        "            next_max = max([self.q_table.get((self.get_state_key(next_state), a), 0)\n",
        "                          for a in valid_demos if a != action], default=0)\n",
        "\n",
        "            self.q_table[(current_state_key, action)] = (\n",
        "                (1 - self.alpha) * self.q_table.get((current_state_key, action), 0) +\n",
        "                self.alpha * (reward + self.gamma * next_max)\n",
        "            )\n",
        "\n",
        "        return [self.demo_pool[i] for i in selected]\n",
        "\n",
        "    def calculate_reward(self, input_embedding, selected_indices):\n",
        "        demo_embeddings = self.demo_embeddings[selected_indices]\n",
        "        similarities = np.dot(demo_embeddings, input_embedding)\n",
        "        relevance = np.mean(similarities)\n",
        "\n",
        "        diversity = self.diversity_score(selected_indices)\n",
        "        max_entropy = np.log(self.num_classes)\n",
        "        normalized_diversity = diversity / max_entropy\n",
        "\n",
        "        return 0.5 * normalized_diversity + 0.5 * relevance\n",
        "\n",
        "sst5 = load_dataset(\"SetFit/sst5\")\n",
        "train_demos = sst5[\"train\"]#.select(range(1000))\n",
        "test_samples = sst5[\"validation\"]#.select(range(100))\n",
        "\n",
        "model_id = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"low_cpu_mem_usage\": True}\n",
        ")\n",
        "\n",
        "rde_selector = RDESelector(train_demos, num_classes=5)\n",
        "\n",
        "label_map = [\n",
        "    \"negative\",\n",
        "    \"somewhat negative\",\n",
        "    \"neutral\",\n",
        "    \"somewhat positive\",\n",
        "    \"positive\"\n",
        "]\n",
        "\n",
        "def format_prompt(demos, test_sample):\n",
        "    prompt = \"Analyze sentiment of these movie reviews. Choose from: negative, somewhat negative, neutral, somewhat positive, positive.\\n\\n\"\n",
        "    for demo in demos:\n",
        "        sentiment = label_map[demo['label']]\n",
        "        prompt += f\"Review: {demo['text']}\\nSentiment: {sentiment}\\n\\n\"\n",
        "\n",
        "    prompt += f\"Review: {test_sample['text']}\\nSentiment:\"\n",
        "    return prompt\n",
        "\n",
        "correct = 0\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    selected_demos = rde_selector.select_demos(sample, k=5)\n",
        "    prompt = format_prompt(selected_demos, sample)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=15,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    generated = outputs[0]['generated_text'].lower()\n",
        "    predicted = None\n",
        "\n",
        "    for label in label_map:\n",
        "        if label in generated:\n",
        "            predicted = label_map.index(label)\n",
        "            break\n",
        "\n",
        "    actual = sample['label']\n",
        "\n",
        "    if predicted is None:\n",
        "        predicted = 2\n",
        "\n",
        "    if predicted == actual:\n",
        "        correct += 1\n",
        "\n",
        "    color_code = \"\\033[92m\" if actual == predicted else \"\\033[91m\"\n",
        "    print(f\"Sample {idx+1}:\")\n",
        "    print(f\"  Predicted: {label_map[predicted]} | Actual: {label_map[actual]}\")\n",
        "    print(f\"{color_code}  Result: {'CORRECT' if actual == predicted else 'INCORRECT'}\\033[0m\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\nFinal Accuracy: {correct/len(test_samples):.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemma SST5\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class RDESelector:\n",
        "    def __init__(self, demo_pool, num_classes, q_table=None):\n",
        "        self.demo_pool = demo_pool\n",
        "        self.num_classes = num_classes\n",
        "        self.q_table = q_table if q_table else {}\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 0.2\n",
        "\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.demo_embeddings = self.embedding_model.encode(\n",
        "            [d['text'] for d in demo_pool],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "    def diversity_score(self, selected_indices):\n",
        "        answer_counts = np.zeros(self.num_classes)\n",
        "        for idx in selected_indices:\n",
        "            answer_counts[self.demo_pool[idx]['label']] += 1\n",
        "        entropy = -np.sum((answer_counts/np.sum(answer_counts)) *\n",
        "                        np.log(answer_counts/np.sum(answer_counts) + 1e-9))\n",
        "        return entropy\n",
        "\n",
        "    def get_state_key(self, current_state):\n",
        "        return tuple(sorted(current_state['selected']))\n",
        "\n",
        "    def select_demos(self, input_sample, k=5):\n",
        "        selected = []\n",
        "        state = {'input': input_sample, 'selected': []}\n",
        "\n",
        "        input_embedding = self.embedding_model.encode(\n",
        "            input_sample['text'],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        for _ in range(k):\n",
        "            valid_demos = [i for i in range(len(self.demo_pool))\n",
        "                         if i not in state['selected']]\n",
        "\n",
        "            if np.random.random() < self.epsilon:\n",
        "                action = int(np.random.choice(valid_demos))\n",
        "            else:\n",
        "                q_values = [self.q_table.get((self.get_state_key(state), a), 0)\n",
        "                          for a in valid_demos]\n",
        "                action = int(valid_demos[np.argmax(q_values)])\n",
        "\n",
        "            selected.append(action)\n",
        "            state['selected'].append(action)\n",
        "\n",
        "            next_state = state.copy()\n",
        "            next_state['selected'] = selected.copy()\n",
        "            reward = self.calculate_reward(input_embedding, selected)\n",
        "\n",
        "            current_state_key = self.get_state_key(state)\n",
        "            next_max = max([self.q_table.get((self.get_state_key(next_state), a), 0)\n",
        "                          for a in valid_demos if a != action], default=0)\n",
        "\n",
        "            self.q_table[(current_state_key, action)] = (\n",
        "                (1 - self.alpha) * self.q_table.get((current_state_key, action), 0) +\n",
        "                self.alpha * (reward + self.gamma * next_max)\n",
        "            )\n",
        "\n",
        "        return [self.demo_pool[i] for i in selected]\n",
        "\n",
        "    def calculate_reward(self, input_embedding, selected_indices):\n",
        "        demo_embeddings = self.demo_embeddings[selected_indices]\n",
        "        similarities = np.dot(demo_embeddings, input_embedding)\n",
        "        relevance = np.mean(similarities)\n",
        "\n",
        "        diversity = self.diversity_score(selected_indices)\n",
        "        max_entropy = np.log(self.num_classes)\n",
        "        normalized_diversity = diversity / max_entropy\n",
        "\n",
        "        return 0.5 * normalized_diversity + 0.5 * relevance\n",
        "\n",
        "# Load SetFit/sst5 dataset [4][5]\n",
        "sst5 = load_dataset(\"SetFit/sst5\")\n",
        "train_demos = sst5[\"train\"]#.select(range(1000))\n",
        "test_samples = sst5[\"validation\"]#.select(range(100))\n",
        "\n",
        "\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"low_cpu_mem_usage\": True}\n",
        ")\n",
        "pipe.tokenizer.pad_token_id = pipe.model.config.eos_token_id\n",
        "\n",
        "rde_selector = RDESelector(train_demos, num_classes=5)\n",
        "\n",
        "label_map = [\n",
        "    \"negative\",\n",
        "    \"somewhat negative\",\n",
        "    \"neutral\",\n",
        "    \"somewhat positive\",\n",
        "    \"positive\"\n",
        "]\n",
        "\n",
        "def format_prompt(demos, test_sample):\n",
        "    prompt = \"Analyze sentiment of these movie reviews. Choose from: negative, somewhat negative, neutral, somewhat positive, positive.\\n\\n\"\n",
        "    for demo in demos:\n",
        "        sentiment = label_map[demo['label']]\n",
        "        prompt += f\"Review: {demo['text']}\\nSentiment: {sentiment}\\n\\n\"\n",
        "\n",
        "    prompt += f\"Review: {test_sample['text']}\\nSentiment:\"\n",
        "    return prompt\n",
        "\n",
        "correct = 0\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    selected_demos = rde_selector.select_demos(sample, k=5)\n",
        "    prompt = format_prompt(selected_demos, sample)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=15,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    generated = outputs[0]['generated_text'].lower()\n",
        "    predicted = None\n",
        "    for label in label_map:\n",
        "        if label in generated:\n",
        "            predicted = label_map.index(label)\n",
        "            break\n",
        "\n",
        "    actual = sample['label']\n",
        "\n",
        "    if predicted is None:\n",
        "        predicted = 2\n",
        "\n",
        "    if predicted == actual:\n",
        "        correct += 1\n",
        "\n",
        "    color_code = \"\\033[92m\" if actual == predicted else \"\\033[91m\"\n",
        "    print(f\"Sample {idx+1}:\")\n",
        "    print(f\"  Predicted: {label_map[predicted]} | Actual: {label_map[actual]}\")\n",
        "    print(f\"{color_code}  Result: {'CORRECT' if actual == predicted else 'INCORRECT'}\\033[0m\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\nFinal Accuracy: {correct/len(test_samples):.2%}\")\n"
      ],
      "metadata": {
        "id": "bwqMTQLgDp3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llama SST 5\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class RDESelector:\n",
        "    def __init__(self, demo_pool, num_classes, q_table=None):\n",
        "        self.demo_pool = demo_pool\n",
        "        self.num_classes = num_classes\n",
        "        self.q_table = q_table if q_table else {}\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 0.2\n",
        "\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.demo_embeddings = self.embedding_model.encode(\n",
        "            [d['text'] for d in demo_pool],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "    def diversity_score(self, selected_indices):\n",
        "        answer_counts = np.zeros(self.num_classes)\n",
        "        for idx in selected_indices:\n",
        "            answer_counts[self.demo_pool[idx]['label']] += 1\n",
        "        entropy = -np.sum((answer_counts/np.sum(answer_counts)) *\n",
        "                        np.log(answer_counts/np.sum(answer_counts) + 1e-9))\n",
        "        return entropy\n",
        "\n",
        "    def get_state_key(self, current_state):\n",
        "        return tuple(sorted(current_state['selected']))\n",
        "\n",
        "    def select_demos(self, input_sample, k=5):\n",
        "        selected = []\n",
        "        state = {'input': input_sample, 'selected': []}\n",
        "\n",
        "        input_embedding = self.embedding_model.encode(\n",
        "            input_sample['text'],\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "\n",
        "        for _ in range(k):\n",
        "            valid_demos = [i for i in range(len(self.demo_pool))\n",
        "                         if i not in state['selected']]\n",
        "\n",
        "            if np.random.random() < self.epsilon:\n",
        "                action = int(np.random.choice(valid_demos))\n",
        "            else:\n",
        "                q_values = [self.q_table.get((self.get_state_key(state), a), 0)\n",
        "                          for a in valid_demos]\n",
        "                action = int(valid_demos[np.argmax(q_values)])\n",
        "\n",
        "            selected.append(action)\n",
        "            state['selected'].append(action)\n",
        "\n",
        "            next_state = state.copy()\n",
        "            next_state['selected'] = selected.copy()\n",
        "            reward = self.calculate_reward(input_embedding, selected)\n",
        "\n",
        "            current_state_key = self.get_state_key(state)\n",
        "            next_max = max([self.q_table.get((self.get_state_key(next_state), a), 0)\n",
        "                          for a in valid_demos if a != action], default=0)\n",
        "\n",
        "            self.q_table[(current_state_key, action)] = (\n",
        "                (1 - self.alpha) * self.q_table.get((current_state_key, action), 0) +\n",
        "                self.alpha * (reward + self.gamma * next_max)\n",
        "            )\n",
        "\n",
        "        return [self.demo_pool[i] for i in selected]\n",
        "\n",
        "    def calculate_reward(self, input_embedding, selected_indices):\n",
        "        demo_embeddings = self.demo_embeddings[selected_indices]\n",
        "        similarities = np.dot(demo_embeddings, input_embedding)\n",
        "        relevance = np.mean(similarities)\n",
        "\n",
        "        diversity = self.diversity_score(selected_indices)\n",
        "        max_entropy = np.log(self.num_classes)\n",
        "        normalized_diversity = diversity / max_entropy\n",
        "\n",
        "        return 0.5 * normalized_diversity + 0.5 * relevance\n",
        "\n",
        "sst5 = load_dataset(\"SetFit/sst5\")\n",
        "train_demos = sst5[\"train\"]#.select(range(1000))\n",
        "test_samples = sst5[\"validation\"]#.select(range(100))\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"low_cpu_mem_usage\": True}\n",
        ")\n",
        "\n",
        "rde_selector = RDESelector(train_demos, num_classes=5)\n",
        "\n",
        "label_map = [\n",
        "    \"very negative\",\n",
        "    \"negative\",\n",
        "    \"neutral\",\n",
        "    \"positive\",\n",
        "    \"very positive\"\n",
        "]\n",
        "\n",
        "def format_prompt(demos, test_sample):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Perform sentiment analysis on movie reviews. Choose from: very negative, negative, neutral, positive, very positive.\"}\n",
        "    ]\n",
        "\n",
        "    for demo in demos:\n",
        "        messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Review: {demo['text']}\"\n",
        "        })\n",
        "        messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": label_map[demo['label']]\n",
        "        })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Review: {test_sample['text']}\"\n",
        "    })\n",
        "\n",
        "    return tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "correct = 0\n",
        "for idx, sample in enumerate(test_samples):\n",
        "    selected_demos = rde_selector.select_demos(sample, k=5)\n",
        "    prompt = format_prompt(selected_demos, sample)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        max_new_tokens=15,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    generated = outputs[0]['generated_text'][len(prompt):].lower().strip()\n",
        "    predicted = None\n",
        "\n",
        "    for i, label in enumerate(label_map):\n",
        "        if any(term in generated for term in [label.lower(), label.split()[0]]):\n",
        "            predicted = i\n",
        "            break\n",
        "\n",
        "    actual = sample['label']\n",
        "\n",
        "    if predicted is None:\n",
        "        predicted = 2\n",
        "\n",
        "    if predicted == actual:\n",
        "        correct += 1\n",
        "\n",
        "    color_code = \"\\033[92m\" if actual == predicted else \"\\033[91m\"\n",
        "    print(f\"Sample {idx+1}:\")\n",
        "    print(f\"  Predicted: {label_map[predicted]} | Actual: {label_map[actual]}\")\n",
        "    print(f\"{color_code}  Result: {'CORRECT' if actual == predicted else 'INCORRECT'}\\033[0m\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\nFinal Accuracy: {correct/len(test_samples):.2%}\")\n"
      ],
      "metadata": {
        "id": "suBLggmTDsvh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}