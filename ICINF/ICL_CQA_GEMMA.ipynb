{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6281e08-27ce-452c-a626-3cbccbd722a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8efae1b7e0f43eda8e622dcf15dff78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f5c386cc54f29a3807760e39f1444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54eda90fee94424c8111a2324fb12e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9049cba007df446f8173d4f3faa288ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835aed2de4f14a1699e6a97b60073f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bdd4171c9b465880ed535a143eb8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa72a08cee7942148fc2e8a38b4ede9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b63dadc3f5d49a88620610bf1b0a5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f1489807c94e8482e671192dacc6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee37cabee9c74e1aab9423f0f3202446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a78a6fd23a4cb482ae4ebce6502f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab651d4e02d14b73a71bee938c735bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b9a508046c4e1bb92aadc8944ab8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e461e6364f3a4ac5a05ea0ed585c3d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/160k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc79208858f64e73a631297cef357d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a778051ac91f4a98b9bd0859906aba6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cdf524560e49e48847c1f1bc8aef08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa772201b544113b1bcebedaf4f0cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating subsets: 100%|██████████| 100/100 [1:53:57<00:00, 68.37s/it]\n",
      "Testing: 100%|██████████| 500/500 [01:09<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 71.20%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# CommonsenseQA prompt template\n",
    "CSQA_TEMPLATE = \"\"\"Question: {question}\n",
    "A. {choice0}\n",
    "B. {choice1}\n",
    "C. {choice2}\n",
    "D. {choice3}\n",
    "E. {choice4}\n",
    "Answer: {answer}\\n\\n\"\"\"\n",
    "\n",
    "def format_example(example):\n",
    "    choices = example[\"choices\"][\"text\"]\n",
    "    return CSQA_TEMPLATE.format(\n",
    "        question=example[\"question\"],\n",
    "        choice0=choices[0],\n",
    "        choice1=choices[1],\n",
    "        choice2=choices[2],\n",
    "        choice3=choices[3],\n",
    "        choice4=choices[4],\n",
    "        answer=example[\"answerKey\"]\n",
    "    )\n",
    "\n",
    "def get_label_probs(prompt, question, choices):\n",
    "    full_input = prompt + f\"\"\"Question: {question}\n",
    "A. {choices[0]}\n",
    "B. {choices[1]}\n",
    "C. {choices[2]}\n",
    "D. {choices[3]}\n",
    "E. {choices[4]}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(full_input, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "\n",
    "    label_tokens = [tokenizer(f\" {c}\")[\"input_ids\"][-1] for c in [\"A\", \"B\", \"C\", \"D\", \"E\"]]\n",
    "    last_token_logits = outputs[0, -1, label_tokens]\n",
    "    return torch.softmax(last_token_logits, dim=-1).cpu().numpy()\n",
    "\n",
    "def evaluate_subset(Si, val_set):\n",
    "    prompt = \"\".join([format_example(ex) for ex in Si])\n",
    "    correct = 0\n",
    "    for ex in val_set:\n",
    "        probs = get_label_probs(prompt, ex[\"question\"], ex[\"choices\"][\"text\"])\n",
    "        pred_idx = np.argmax(probs)\n",
    "        pred_choice = [\"A\", \"B\", \"C\", \"D\", \"E\"][pred_idx]\n",
    "        if pred_choice == ex[\"answerKey\"]:\n",
    "            correct += 1\n",
    "    return correct / len(val_set)\n",
    "\n",
    "def compute_influences(train_set, val_set, k=5, M=100):\n",
    "    # Balanced subset sampling\n",
    "    class_counts = defaultdict(int)\n",
    "    for ex in train_set:\n",
    "        class_counts[ex[\"answerKey\"]] += 1\n",
    "    \n",
    "    k_per_class = max(1, k // len(class_counts))\n",
    "    subsets = []\n",
    "    for _ in range(M):\n",
    "        Si = []\n",
    "        for label in class_counts:\n",
    "            candidates = [ex for ex in train_set if ex[\"answerKey\"] == label]\n",
    "            Si.extend(np.random.choice(candidates, k_per_class, replace=False))\n",
    "        Si = list(np.random.choice(Si, k, replace=False))\n",
    "        subsets.append(Si)\n",
    "    \n",
    "    # Sequential evaluation\n",
    "    D = []\n",
    "    for Si in tqdm(subsets, desc=\"Evaluating subsets\"):\n",
    "        D.append(evaluate_subset(Si, val_set))\n",
    "    \n",
    "    # Calculate influences\n",
    "    influence_scores = defaultdict(list)\n",
    "    for idx, ex in enumerate(train_set):\n",
    "        included = []\n",
    "        excluded = []\n",
    "        for Si, acc in zip(subsets, D):\n",
    "            if ex in Si:\n",
    "                included.append(acc)\n",
    "            else:\n",
    "                excluded.append(acc)\n",
    "        \n",
    "        Nj = len(included)\n",
    "        Mj = len(D) - Nj\n",
    "        if Nj > 0 and Mj > 0:\n",
    "            influence = (sum(included)/Nj) - (sum(excluded)/Mj)\n",
    "        else:\n",
    "            influence = 0\n",
    "        influence_scores[idx] = influence\n",
    "    \n",
    "    return influence_scores\n",
    "\n",
    "def load_csqa(split=\"train\", num_samples=1000):\n",
    "    dataset = load_dataset(\"commonsense_qa\", split=split)\n",
    "    dataset = dataset.shuffle(seed=42).select(range(min(num_samples, len(dataset))))\n",
    "    if split!=\"train\":\n",
    "        full_val = load_dataset(\"commonsense_qa\", split=\"validation\").shuffle(seed=42)\n",
    "        val_set = full_val.select(range(0, 500))  # First 500 for validation\n",
    "        test_set = full_val.select(range(500, 1000))\n",
    "        return val_set, test_set\n",
    "    return dataset\n",
    "\n",
    "def run_experiment():\n",
    "    # Load CommonsenseQA\n",
    "    train_set = load_csqa(\"train\", 5000)\n",
    "    val_set, test_set = load_csqa(\"validation\", 1000)\n",
    "\n",
    "    # Compute influences\n",
    "    influence_scores = compute_influences(train_set, val_set, k=5, M=100)\n",
    "    \n",
    "    # Select top examples\n",
    "    sorted_indices = sorted(influence_scores, key=influence_scores.get, reverse=True)[:5]\n",
    "    top_examples = [train_set[i] for i in sorted_indices]\n",
    "    \n",
    "    # Final evaluation\n",
    "    prompt = \"\".join([format_example(ex) for ex in top_examples])\n",
    "    correct = 0\n",
    "    for ex in tqdm(test_set, desc=\"Testing\"):\n",
    "        probs = get_label_probs(prompt, ex[\"question\"], ex[\"choices\"][\"text\"])\n",
    "        pred_idx = np.argmax(probs)\n",
    "        pred_choice = [\"A\", \"B\", \"C\", \"D\", \"E\"][pred_idx]\n",
    "        if pred_choice == ex[\"answerKey\"]:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f\"Final Test Accuracy: {correct/len(test_set):.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9656d-c3d3-4ca0-9dd2-132d3cd28a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
