{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2580591-27ac-411f-a067-f09fc18a2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c97ddb30-9e3f-421d-9230-02c7098cd44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.13437108/ipykernel_3198381/2257804631.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_train_full.groupby('label', group_keys=False).apply(lambda x: x.sample(n=1500, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df_train_full = pd.read_parquet(\"hf://datasets/wangrongsheng/ag_news/\" + splits[\"train\"])\n",
    "\n",
    "df_sampled = df_train_full.groupby('label', group_keys=False).apply(lambda x: x.sample(n=1500, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "df_train, df_val = train_test_split(\n",
    "    df_sampled,\n",
    "    test_size=1000,\n",
    "    stratify=df_sampled['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_test_full = pd.read_parquet(\"hf://datasets/wangrongsheng/ag_news/\" + splits[\"test\"])\n",
    "df_test = df_test_full.sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69e2742-4cb6-478a-9914-6914105169c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 2), (1000, 2), (1000, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab121c7a-a7b1-4439-831f-7e739ff4fbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26987c3daf864c2a861a9fc3fd6fe76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.13437108/ipykernel_3198381/4293468449.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_train_full.groupby('label', group_keys=False).apply(\n",
      "Evaluating subsets: 100%|██████████| 100/100 [4:33:08<00:00, 163.88s/it] \n",
      "Testing: 100%|██████████| 1000/1000 [02:58<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 52.40%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# AG News template\n",
    "AG_NEWS_TEMPLATE = \"Headline: {text}\\nCategory: {label}\\n\\n\"\n",
    "\n",
    "def format_example(example):\n",
    "    return AG_NEWS_TEMPLATE.format(\n",
    "        text=example[\"text\"],\n",
    "        label=example[\"label\"]\n",
    "    )\n",
    "\n",
    "def get_label_probs(prompt, text):\n",
    "    full_input = prompt + f\"Headline: {text}\\nCategory:\"\n",
    "    inputs = tokenizer(full_input, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    \n",
    "    # Label tokens for 4-class AG News\n",
    "    label_tokens = [tokenizer(f\" {i}\")[\"input_ids\"][-1] for i in range(4)]\n",
    "    last_token_logits = outputs[0, -1, label_tokens]\n",
    "    return torch.softmax(last_token_logits, dim=-1).cpu().numpy()\n",
    "\n",
    "def evaluate_subset(Si, val_set):\n",
    "    prompt = \"\".join([format_example(ex) for ex in Si])\n",
    "    correct = 0\n",
    "    for ex in val_set:\n",
    "        probs = get_label_probs(prompt, ex[\"text\"])\n",
    "        if np.argmax(probs) == ex[\"label\"]:\n",
    "            correct += 1\n",
    "    return correct / len(val_set)\n",
    "\n",
    "def load_agnews():\n",
    "    splits = {'train': 'data/train-00000-of-00001.parquet', \n",
    "             'test': 'data/test-00000-of-00001.parquet'}\n",
    "    \n",
    "    # Load and sample data\n",
    "    df_train_full = pd.read_parquet(\"hf://datasets/wangrongsheng/ag_news/\" + splits[\"train\"])\n",
    "    df_sampled = df_train_full.groupby('label', group_keys=False).apply(\n",
    "        lambda x: x.sample(n=1500, random_state=42)).reset_index(drop=True)\n",
    "    \n",
    "    # Train/val split\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_sampled,\n",
    "        test_size=1000,\n",
    "        stratify=df_sampled['label'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Test set\n",
    "    df_test_full = pd.read_parquet(\"hf://datasets/wangrongsheng/ag_news/\" + splits[\"test\"])\n",
    "    df_test = df_test_full.sample(n=1000, random_state=42)\n",
    "    \n",
    "    # Convert to HuggingFace datasets\n",
    "    train_set = Dataset.from_pandas(df_train[['text', 'label']])\n",
    "    val_set = Dataset.from_pandas(df_val[['text', 'label']])\n",
    "    test_set = Dataset.from_pandas(df_test[['text', 'label']])\n",
    "    \n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def compute_influences(train_set, val_set, k=5, M=100):\n",
    "    # Balanced subset sampling\n",
    "    class_counts = defaultdict(int)\n",
    "    for ex in train_set:\n",
    "        class_counts[ex[\"label\"]] += 1\n",
    "    \n",
    "    k_per_class = max(1, k // len(class_counts))\n",
    "    subsets = []\n",
    "    for _ in range(M):\n",
    "        Si = []\n",
    "        for label in class_counts:\n",
    "            candidates = [ex for ex in train_set if ex[\"label\"] == label]\n",
    "            Si.extend(np.random.choice(candidates, k_per_class, replace=False))\n",
    "        Si = list(np.random.choice(Si, k))\n",
    "        subsets.append(Si)\n",
    "    \n",
    "    # Sequential evaluation\n",
    "    D = []\n",
    "    for Si in tqdm(subsets, desc=\"Evaluating subsets\"):\n",
    "        D.append(evaluate_subset(Si, val_set))\n",
    "    \n",
    "    # Calculate influences\n",
    "    influence_scores = defaultdict(list)\n",
    "    for idx, ex in enumerate(train_set):\n",
    "        included = []\n",
    "        excluded = []\n",
    "        for Si, acc in zip(subsets, D):\n",
    "            if ex in Si:\n",
    "                included.append(acc)\n",
    "            else:\n",
    "                excluded.append(acc)\n",
    "        \n",
    "        Nj = len(included)\n",
    "        Mj = len(D) - Nj\n",
    "        if Nj > 0 and Mj > 0:\n",
    "            influence = (sum(included)/Nj) - (sum(excluded)/Mj)\n",
    "        else:\n",
    "            influence = 0\n",
    "        influence_scores[idx] = influence\n",
    "    \n",
    "    return influence_scores\n",
    "\n",
    "def run_experiment():\n",
    "    # Load AG News\n",
    "    train_set, val_set, test_set = load_agnews()\n",
    "    \n",
    "    # Compute influences\n",
    "    influence_scores = compute_influences(train_set, val_set, k=5, M=100)\n",
    "    \n",
    "    # Select top examples\n",
    "    sorted_indices = sorted(influence_scores, key=influence_scores.get, reverse=True)[:5]\n",
    "    top_examples = [train_set[i] for i in sorted_indices]\n",
    "    \n",
    "    # Final evaluation\n",
    "    prompt = \"\".join([format_example(ex) for ex in top_examples])\n",
    "    correct = 0\n",
    "    for ex in tqdm(test_set, desc=\"Testing\"):\n",
    "        probs = get_label_probs(prompt, ex[\"text\"])\n",
    "        if np.argmax(probs) == ex[\"label\"]:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f\"Final Test Accuracy: {correct/len(test_set):.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9426b0d0-e2bb-4ede-bcdd-726dc9973ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/scratch/user/vp190545/huggingface_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6b268b-f5a2-428f-acf8-fc3992b1c64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3da3e473b54b2c922f66a3e54e42e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/job.13437108/ipykernel_3229544/1871702809.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df_train_full.groupby('label', group_keys=False).apply(\n",
      "Evaluating subsets: 100%|██████████| 100/100 [4:35:27<00:00, 165.27s/it] \n",
      "Testing: 100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 24.80%\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# AG News template\n",
    "AG_NEWS_TEMPLATE = \"Headline: {text}\\nCategory: {label}\\n\\n\"\n",
    "\n",
    "def format_example(example):\n",
    "    return AG_NEWS_TEMPLATE.format(\n",
    "        text=example[\"text\"],\n",
    "        label=example[\"label\"]\n",
    "    )\n",
    "\n",
    "def get_label_probs(prompt, text):\n",
    "    full_input = prompt + f\"Headline: {text}\\nCategory:\"\n",
    "    inputs = tokenizer(full_input, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "    \n",
    "    # Label tokens for 4-class AG News\n",
    "    label_tokens = [tokenizer(f\" {i}\")[\"input_ids\"][-1] for i in range(4)]\n",
    "    last_token_logits = outputs[0, -1, label_tokens]\n",
    "    return torch.softmax(last_token_logits, dim=-1).cpu().numpy()\n",
    "\n",
    "def evaluate_subset(Si, val_set):\n",
    "    prompt = \"\".join([format_example(ex) for ex in Si])\n",
    "    correct = 0\n",
    "    for ex in val_set:\n",
    "        probs = get_label_probs(prompt, ex[\"text\"])\n",
    "        if np.argmax(probs) == ex[\"label\"]:\n",
    "            correct += 1\n",
    "    return correct / len(val_set)\n",
    "\n",
    "def load_agnews():\n",
    "    splits = {'train': 'data/train-00000-of-00001.parquet', \n",
    "             'test': 'data/test-00000-of-00001.parquet'}\n",
    "    \n",
    "    # Load and sample data\n",
    "    df_train_full = pd.read_parquet(\"hf://datasets/wangrongsheng/ag_news/\" + splits[\"train\"])\n",
    "    df_sampled = df_train_full.groupby('label', group_keys=False).apply(\n",
    "        lambda x: x.sample(n=1500, random_state=42)).reset_index(drop=True)\n",
    "    \n",
    "    # Train/val split\n",
    "    df_train, df_val = train_test_split(\n",
    "        df_sampled,\n",
    "        test_size=1000,\n",
    "        stratify=df_sampled['label'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Test set\n",
    "    df_test_full = pd.read_parquet(\"hf://datasets/wangrongsheng/ag_news/\" + splits[\"test\"])\n",
    "    df_test = df_test_full.sample(n=1000, random_state=42)\n",
    "    \n",
    "    # Convert to HuggingFace datasets\n",
    "    train_set = Dataset.from_pandas(df_train[['text', 'label']])\n",
    "    val_set = Dataset.from_pandas(df_val[['text', 'label']])\n",
    "    test_set = Dataset.from_pandas(df_test[['text', 'label']])\n",
    "    \n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def compute_influences(train_set, val_set, k=5, M=100):\n",
    "    # Balanced subset sampling\n",
    "    class_counts = defaultdict(int)\n",
    "    for ex in train_set:\n",
    "        class_counts[ex[\"label\"]] += 1\n",
    "    \n",
    "    k_per_class = max(1, k // len(class_counts))\n",
    "    subsets = []\n",
    "    for _ in range(M):\n",
    "        Si = []\n",
    "        for label in class_counts:\n",
    "            candidates = [ex for ex in train_set if ex[\"label\"] == label]\n",
    "            Si.extend(np.random.choice(candidates, k_per_class, replace=False))\n",
    "        Si = list(np.random.choice(Si, k))\n",
    "        subsets.append(Si)\n",
    "    \n",
    "    # Sequential evaluation\n",
    "    D = []\n",
    "    for Si in tqdm(subsets, desc=\"Evaluating subsets\"):\n",
    "        D.append(evaluate_subset(Si, val_set))\n",
    "    \n",
    "    # Calculate influences\n",
    "    influence_scores = defaultdict(list)\n",
    "    for idx, ex in enumerate(train_set):\n",
    "        included = []\n",
    "        excluded = []\n",
    "        for Si, acc in zip(subsets, D):\n",
    "            if ex in Si:\n",
    "                included.append(acc)\n",
    "            else:\n",
    "                excluded.append(acc)\n",
    "        \n",
    "        Nj = len(included)\n",
    "        Mj = len(D) - Nj\n",
    "        if Nj > 0 and Mj > 0:\n",
    "            influence = (sum(included)/Nj) - (sum(excluded)/Mj)\n",
    "        else:\n",
    "            influence = 0\n",
    "        influence_scores[idx] = influence\n",
    "    \n",
    "    return influence_scores\n",
    "\n",
    "def run_experiment():\n",
    "    # Load AG News\n",
    "    train_set, val_set, test_set = load_agnews()\n",
    "    \n",
    "    # Compute influences\n",
    "    influence_scores = compute_influences(train_set, val_set, k=5, M=100)\n",
    "    \n",
    "    # Select top examples\n",
    "    sorted_indices = sorted(influence_scores, key=influence_scores.get, reverse=True)[:5]\n",
    "    top_examples = [train_set[i] for i in sorted_indices]\n",
    "    \n",
    "    # Final evaluation\n",
    "    prompt = \"\".join([format_example(ex) for ex in top_examples])\n",
    "    correct = 0\n",
    "    for ex in tqdm(test_set, desc=\"Testing\"):\n",
    "        probs = get_label_probs(prompt, ex[\"text\"])\n",
    "        if np.argmax(probs) == ex[\"label\"]:\n",
    "            correct += 1\n",
    "    \n",
    "    print(f\"Final Test Accuracy: {correct/len(test_set):.2%}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738ef23-422a-421a-98ea-2f1a9de7d12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
